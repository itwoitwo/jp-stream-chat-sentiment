{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e92f2a0-305b-4503-9cd6-d0388c399fd6",
   "metadata": {},
   "source": [
    "### 基本的にShift+Enterで順番に実行していく\n",
    "* 感情分析をスキップしてチャット内容の閲覧とダウンロードをする場合は該当箇所を飛ばして実行\n",
    "#### 感情分析を実行する場合はGPUを有効にしてセッションを再起動しておく\n",
    "* 編集＞ノートブックの設定＞T4 GPU等にチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71903c49-1870-49f7-ba5a-46463d3d1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完了後にセッションの再起動を求められた場合は再起動する\n",
    "!pip install dash yt_dlp datasets fugashi ipadic unidic-lite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012b75f-c208-4fa6-a22a-bb1720081159",
   "metadata": {},
   "source": [
    "### 関数の定義等(必ず実行する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418d751-b942-448b-acb4-ddd44da6715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645ba54-e9e2-46ff-a10a-5fbcf96f5bfe",
   "metadata": {},
   "source": [
    "#### ↑ cudaと表示されていればGPUが有効となっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c7fbf-8b0b-40e7-baf8-e127361f15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from charset_normalizer import detect\n",
    "from dash import Dash, callback, dcc, html, Input, Output, State, dash_table\n",
    "import plotly.graph_objects as go\n",
    "from urllib.parse import urlparse\n",
    "from yt_dlp import YoutubeDL\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e58c5-0efd-46bb-86ef-ed37091b8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数の定義\n",
    "def exec_download(url, path='/content'):\n",
    "    parsed_url = urlparse(url)\n",
    "    df = None\n",
    "    metadata = None\n",
    "    if 'youtube' in parsed_url.netloc:\n",
    "        df, metadata = download_youtube_chats(url, path)\n",
    "        print('ダウンロードが完了しました！')\n",
    "    elif 'twitch' in parsed_url.netloc:\n",
    "        video_id = parsed_url.path.split('/')[-1]\n",
    "        if video_id == '':\n",
    "            print('アーカイブページのURL:https://www.twitch.tv/videos/xxxxxxxxxx を入力してください。')\n",
    "            return df, metadata\n",
    "        print('チャットのダウンロード中...')\n",
    "        df, metadata = download_twitch_chats(video_id)\n",
    "        print('ダウンロードが完了しました！')\n",
    "    else:\n",
    "        print('youtubeかtwitchのurlを入力してください。')\n",
    "    return df, metadata\n",
    "\n",
    "\n",
    "def json_to_df(path):\n",
    "    chats = []\n",
    "    timestamps = []\n",
    "    minutes = []\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.strip() == '':\n",
    "                continue\n",
    "            l_json = json.loads(line)\n",
    "            j_action = l_json['replayChatItemAction']['actions'][0]\n",
    "            if 'addChatItemAction' in j_action:\n",
    "                item = j_action['addChatItemAction']['item']\n",
    "                if 'liveChatTextMessageRenderer' in item:\n",
    "                    message_runs = item['liveChatTextMessageRenderer']['message']['runs']\n",
    "                    if message_runs and 'text' in message_runs[0]:\n",
    "                        chat = message_runs[0]['text']\n",
    "                        timestamp = int(l_json['replayChatItemAction']['videoOffsetTimeMsec']) // 1000\n",
    "                        chats.append(chat)\n",
    "                        timestamps.append(timestamp)\n",
    "                        minutes.append(int(timestamp // 60))\n",
    "\n",
    "    return pd.DataFrame({'chat': chats, 'second': timestamps, 'minute': minutes})\n",
    "\n",
    "\n",
    "def get_json_data(video_id, cursor):\n",
    "    loop_data = json.dumps([\n",
    "        {\n",
    "            \"operationName\": \"VideoCommentsByOffsetOrCursor\",\n",
    "            \"variables\": {\n",
    "                \"videoID\": video_id,\n",
    "                \"cursor\": cursor\n",
    "            },\n",
    "            \"extensions\": {\n",
    "                \"persistedQuery\": {\n",
    "                    \"version\": 1,\n",
    "                    \"sha256Hash\": \"b70a3591ff0f4e0313d126c6a1502d79a1c02baebb288227c582044aa76adf6a\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    return loop_data\n",
    "\n",
    "\n",
    "def download_youtube_chats(url, path):\n",
    "    res = exec_youtube_dl(url, path)\n",
    "    title = res['title']\n",
    "    video_id = res['id']\n",
    "    timestamp = pd.to_datetime(res['timestamp'], unit='s', utc=True)\n",
    "\n",
    "    json_path = f\"{path}/{video_id}.live_chat.json\"\n",
    "    df = json_to_df(json_path)\n",
    "\n",
    "    metadata = {\n",
    "        'タイトル': title,\n",
    "        '放送日時': timestamp.tz_convert('Asia/Tokyo').strftime(\"%Y/%m/%d/%H:%M\"),\n",
    "        'url': url,\n",
    "    }\n",
    "\n",
    "    return df, metadata\n",
    "\n",
    "\n",
    "def exec_youtube_dl(url, path):\n",
    "    output_path = f'{path}/%(id)s'\n",
    "\n",
    "    with YoutubeDL({\n",
    "        'format': 'best',\n",
    "        'outtmpl': output_path,\n",
    "        'writesubtitles': True,\n",
    "        'skip_download': True\n",
    "    }) as ydl:\n",
    "        res = ydl.extract_info(url, download=False)\n",
    "        ydl.download([url])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def download_twitch_chats(video_id):\n",
    "    api_url = 'https://gql.twitch.tv/gql'\n",
    "    first_data = json.dumps([\n",
    "        {\n",
    "            \"operationName\": \"VideoCommentsByOffsetOrCursor\",\n",
    "            \"variables\": {\n",
    "                \"videoID\": video_id,\n",
    "                \"contentOffsetSeconds\": 0\n",
    "            },\n",
    "            \"extensions\": {\n",
    "                \"persistedQuery\": {\n",
    "                    \"version\": 1,\n",
    "                    \"sha256Hash\": \"b70a3591ff0f4e0313d126c6a1502d79a1c02baebb288227c582044aa76adf6a\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # 1回目のセッションスタート\n",
    "    session = requests.Session()\n",
    "    session.headers = {'Client-ID': 'kd1unb4b3q4t58fwlpcbzcbnm76a8fp', 'content-type': 'application/json'}\n",
    "\n",
    "    response = session.post(\n",
    "        api_url,\n",
    "        first_data,\n",
    "        timeout=10\n",
    "    )\n",
    "\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    chats = []\n",
    "    seconds = []\n",
    "    minutes = []\n",
    "    for comment in data[0]['data']['video']['comments']['edges']:\n",
    "        chats.append(comment['node']['message']['fragments'][0]['text'])\n",
    "        timestamp = int(comment['node']['contentOffsetSeconds'])\n",
    "        seconds.append(timestamp)\n",
    "        minutes.append(timestamp // 60)\n",
    "\n",
    "    cursor = None\n",
    "    if data[0]['data']['video']['comments']['pageInfo']['hasNextPage']:\n",
    "        cursor = data[0]['data']['video']['comments']['edges'][-1]['cursor']\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # session loop\n",
    "    while cursor:\n",
    "        response = session.post(\n",
    "            api_url,\n",
    "            get_json_data(video_id, cursor),\n",
    "            timeout=10\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        for comment in data[0]['data']['video']['comments']['edges']:\n",
    "            chats.append(comment['node']['message']['fragments'][0]['text'])\n",
    "            timestamp = int(comment['node']['contentOffsetSeconds'])\n",
    "            seconds.append(timestamp)\n",
    "            minutes.append(timestamp // 60)\n",
    "\n",
    "        if data[0]['data']['video']['comments']['pageInfo']['hasNextPage']:\n",
    "            cursor = data[0]['data']['video']['comments']['edges'][-1]['cursor']\n",
    "            time.sleep(0.1)\n",
    "        else:\n",
    "            cursor = None\n",
    "\n",
    "    metadata = {'url': f\"https://www.twitch.tv/videos/{video_id}\"}\n",
    "    df = pd.DataFrame({'chat': chats, 'second': seconds, 'minute': minutes})\n",
    "    return df, metadata\n",
    "\n",
    "\n",
    "def classify_emotions(model, tokenizer, texts, batch_size, tokens_max_len, device):\n",
    "    model.to(device)\n",
    "    dataset = Dataset.from_dict({'text': texts})\n",
    "    dataset = dataset.map(\n",
    "        lambda x: tokenizer(x['text'], truncation=True, padding='max_length', max_length=tokens_max_len),\n",
    "        batched=True)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    results = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='感情分析の進捗', unit='batch'):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            results.extend([model.config.id2label[pred.item()] for pred in predictions])\n",
    "    return results\n",
    "\n",
    "# Dash用の変数と関数を定義\n",
    "EMOTION_COLORS = {\n",
    "    '喜び': '#FFD700',  # ゴールド（黄金色）\n",
    "    '期待': '#FFA07A',  # ライトサーモン\n",
    "    '信頼': '#90EE90',  # ライトグリーン\n",
    "    '驚き': '#00CED1',  # ダークターコイズ\n",
    "    '悲しみ': '#6495ED',  # コーンフラワーブルー\n",
    "    '恐れ': '#4682B4',  # スティールブルー\n",
    "    '嫌悪': '#8B008B',  # ダークマゼンタ\n",
    "    '怒り': '#CD5C5C',  # インディアンレッド\n",
    "    '中立': 'grey',\n",
    "    '未分類': 'grey'\n",
    "}\n",
    "\n",
    "def create_table(df):\n",
    "    return html.Div([\n",
    "            dash_table.DataTable(\n",
    "                data=df.to_dict('records'),\n",
    "                columns=[{'name': i, 'id': i} for i in df.columns],\n",
    "                page_size=10\n",
    "            ),\n",
    "            html.Hr()\n",
    "        ])\n",
    "\n",
    "def parse_contents(contents):\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "\n",
    "    try:\n",
    "        detected = detect(decoded)\n",
    "        encoding = detected['encoding']\n",
    "\n",
    "        # ファイルの内容を文字列として読み込む\n",
    "        file_content = io.StringIO(decoded.decode(encoding))\n",
    "\n",
    "        # 最初の行を読み取り、メタデータかどうかを確認\n",
    "        first_line = file_content.readline().strip()\n",
    "        metadata = {}\n",
    "        if first_line.startswith('# attrs:'):\n",
    "            metadata = json.loads(first_line[8:])\n",
    "            df = pd.read_csv(file_content)\n",
    "        else:\n",
    "            file_content.seek(0)  # ファイルポインタを先頭に戻す\n",
    "            df = pd.read_csv(file_content)\n",
    "        table = create_table(df)\n",
    "        return table, df, metadata\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return html.Div([\n",
    "            'ファイルの処理中にエラーが発生しました。'\n",
    "        ]), None, {}\n",
    "\n",
    "def create_plot(df, bin_width):\n",
    "    if df is None:\n",
    "        return None\n",
    "    # ビンの設定\n",
    "    max_minutes = df['minute'].max()\n",
    "\n",
    "    # ヒストグラムの作成\n",
    "    fig = go.Figure()\n",
    "    if 'emotion' not in df.columns:\n",
    "        df['emotion'] = '未分類'\n",
    "    for emotion in reversed(EMOTION_COLORS.keys()):\n",
    "        emotion_data = df[df['emotion'] == emotion]\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=emotion_data['minute'],\n",
    "            name=emotion,\n",
    "            marker_color=EMOTION_COLORS.get(emotion, 'grey'),\n",
    "            xbins=dict(start=0, end=max_minutes, size=bin_width),\n",
    "            autobinx=False\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        title=None,\n",
    "        xaxis_title='時間 (分)',\n",
    "        yaxis_title='コメント数',\n",
    "        margin=dict(\n",
    "            l=50, r=50, t=30, b=50\n",
    "        ),\n",
    "        legend=dict(\n",
    "            font=dict(\n",
    "                size=16\n",
    "            ),\n",
    "            itemclick='toggleothers',\n",
    "            itemdoubleclick='toggle'\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            rangemode='nonnegative',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            rangemode='nonnegative',\n",
    "        ),\n",
    "        modebar=dict(\n",
    "            remove=['select', 'lasso']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if bin_width == 1:\n",
    "        fig.update_traces(hovertemplate='%{x} - %{x}59秒<br>%{y}')\n",
    "        fig.update_xaxes(dtick=5, ticksuffix='分')\n",
    "    else:\n",
    "        tick_vals = list(range(0, int(max_minutes) + bin_width, bin_width))\n",
    "        tick_text = [f'{i}分' for i in tick_vals]\n",
    "        fig.update_xaxes(tickvals=tick_vals, ticktext=tick_text, ticksuffix='分59秒')\n",
    "\n",
    "    return fig\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Upload(\n",
    "        id='upload-data',\n",
    "        children=html.Div([\n",
    "            'ドラッグ&ドロップまたは ',\n",
    "            html.A('ファイルを選択')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '100%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px'\n",
    "        },\n",
    "        multiple=False\n",
    "    ),\n",
    "    html.Div(id='output-data-upload'),\n",
    "    html.Div([\n",
    "        html.Div(id='metadata-output', style={'display': 'inline-block', 'verticalAlign': 'top', 'width': '80%'}),\n",
    "        html.Div([\n",
    "            html.Button('Download CSV', id='btn-download-csv', \n",
    "                        style={'fontSize': '0.8em', 'padding': '5px 10px'})\n",
    "        ], style={'display': 'inline-block', 'verticalAlign': 'top', 'width': '20%', 'textAlign': 'right'})\n",
    "    ], style={'marginBottom': '20px'}),\n",
    "    dcc.Graph(id='histogram'),\n",
    "    html.Div([\n",
    "        html.Label('コメント数を集計する時間の長さ:'),\n",
    "        dcc.Slider(\n",
    "            id='bin-slider',\n",
    "            min=1,\n",
    "            max=10,\n",
    "            step=1,\n",
    "            value=1,\n",
    "            marks={i: f'{i}分' for i in range(1, 11)},\n",
    "        )\n",
    "    ]),\n",
    "    dcc.Download(id='download-dataframe-csv'),\n",
    "])\n",
    "\n",
    "@callback(\n",
    "    [Output('output-data-upload', 'children'),\n",
    "     Output('metadata-output', 'children'),\n",
    "     Output('histogram', 'figure')],\n",
    "    [Input('upload-data', 'contents'),\n",
    "     Input('bin-slider', 'value')]\n",
    ")\n",
    "def update_output(contents, bin_width_minutes):\n",
    "    global global_df\n",
    "    global global_metadata\n",
    "    if contents is None:\n",
    "        df = global_df\n",
    "        if df is None:\n",
    "            return None, None, {}\n",
    "        children = create_table(df)\n",
    "        metadata = global_metadata\n",
    "        metadata_output = format_metadata(metadata) if metadata else None\n",
    "        fig = create_plot(df, bin_width_minutes)\n",
    "        return children, metadata_output, fig\n",
    "\n",
    "    children, df, metadata = parse_contents(contents)\n",
    "\n",
    "    metadata_output = format_metadata(metadata) if metadata else None\n",
    "\n",
    "    fig = create_plot(df, bin_width_minutes)\n",
    "\n",
    "    global_df = df\n",
    "    global_metadata = metadata\n",
    "\n",
    "    return children, metadata_output, fig\n",
    "\n",
    "def format_metadata(metadata):\n",
    "    formatted_metadata = []\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, str) and value.startswith('http'):\n",
    "            formatted_value = html.A(value, href=value, target='_blank')\n",
    "        else:\n",
    "            formatted_value = str(value)\n",
    "        formatted_metadata.append(html.Div([\n",
    "            html.Strong(f\"{key}: \"),\n",
    "            formatted_value\n",
    "        ]))\n",
    "    return html.Div(formatted_metadata)\n",
    "\n",
    "@callback(\n",
    "    Output('download-dataframe-csv', 'data'),\n",
    "    Input('btn-download-csv', 'n_clicks'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def download_csv(n_clicks):\n",
    "    global global_df\n",
    "    global global_metadata\n",
    "    if global_df is not None:\n",
    "        buffer = io.StringIO()\n",
    "        if len(global_metadata) != 0:\n",
    "            buffer.write(f\"# attrs: {json.dumps(global_metadata, ensure_ascii=False)}\\n\")\n",
    "        global_df.to_csv(buffer, index=False, quoting=csv.QUOTE_ALL, escapechar='\\\\', quotechar='\"', encoding='utf-8')\n",
    "        \n",
    "        return dcc.send_string(\n",
    "            buffer.getvalue(),\n",
    "            'chat_data.csv',\n",
    "            'text/csv',\n",
    "        )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed295500-5b5b-4882-9aaf-2b116b7ecade",
   "metadata": {},
   "source": [
    "### URLを入力してチャットをダウンロード\n",
    "* 次のセルをShift+Enterで実行するとURLを聞かれるので、URLを入力してEnter(URL入力中はShift+Enterだとエラーが出ます)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f105c-6a4f-459b-bc3a-af28bd0da5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input('youtubeかtwitchのURLを入力してください。')\n",
    "global_df, global_metadata = exec_download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83702938-8335-4a1e-a9f3-20a8b81cdd35",
   "metadata": {},
   "source": [
    "### 感情分析の実行(スキップしても時間帯毎のチャット数の確認やローカルPCへの保存は可能)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc3e23-2faf-4f99-93bb-ddc884e4901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "tokens_max_len = 64\n",
    "model = AutoModelForSequenceClassification.from_pretrained('iton/YTLive-JaBERT-Emotion-v1')\n",
    "tokenizer = AutoTokenizer.from_pretrained('tohoku-nlp/bert-base-japanese-v3', clean_up_tokenization_spaces=True)\n",
    "global_df['emotion'] = classify_emotions(model, tokenizer, global_df['chat'].tolist(), batch_size, tokens_max_len, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a30a0b-1843-485d-9144-f0d3e59755cc",
   "metadata": {},
   "source": [
    "### アプリの実行(グラフを描画、ローカルPCに保存)\n",
    "* 右側のDownload_csvでローカルPCに分析結果をダウンロード\n",
    "* ドラッグ＆ドロップで過去に保存したチャットのグラフを表示\n",
    "* グラフ内の右上のカメラマークでグラフを画像として保存\n",
    "* グラフ右側の「喜び」などをクリックすると単体表示\n",
    "    * クリックやダブルクリックで切り替え\n",
    "* グラフ下部のスライダーを調整して何分間のチャットをまとめて集計するか変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb4be3-af41-4948-bf90-577e02aaba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(jupyter_mode='inline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
